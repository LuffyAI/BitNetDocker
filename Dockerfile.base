# Dockerfile.base
# Python Version: 3.10
# Base Image: Alpine 3.23
# OS: Alpine Linux
# Description: This Dockerfile sets up a base environment for building and running BitNet with Python 3.10 on Alpine Linux.
# It installs necessary dependencies, clones the BitNet repository at a specific commit, and prepares the environment for BitNet execution.
FROM python:3.10-alpine3.23

# Install dependencies
# https://pkgs.alpinelinux.org/packages
# Clang is a complier for C/C++ code
# Cmake automates dependency management and build process for C/C++ code. Think like Makefiles.
# We all know git.
# build-base is a meta-package that includes the GCC compiler, libc-dev and make.
# pkgconf is a package configuration tool required by BitNet.
RUN apk add --no-cache \
    clang=21.1.2-r2 \
    cmake=4.1.3-r0 \
    git=2.52.0-r0 \
    build-base=0.5-r3 \
    pkgconf=2.5.1-r0 \
    protobuf-dev=31.1-r1 \
    py3-numpy=2.3.5-r0 \
    vim

# Set working directory
WORKDIR /app

# Install Python deps
RUN pip install --no-cache-dir \
    huggingface_hub[cli]==0.20.3

# We clone BitNet at a fixed commit. This ensures that if the repo changes, this won't break the build.
# BitNet is being continually updated and actively researched, and we want a stable base to allow for reproducible builds.
RUN git clone --recursive https://github.com/microsoft/BitNet.git /app/BitNet && \
    cd /app/BitNet && \
    git checkout ade47a535cac7727dedde25b37b97774699e32d3 && \
    git submodule update --init --recursive && \
    rm -rf .git

# Download GGUF model (This is the default model used in BitNet)
RUN python -m huggingface_hub.commands.huggingface_cli download \
    microsoft/bitnet-b1.58-2B-4T-gguf \
    --include "ggml-model-i2_s.gguf" \
    --local-dir /app/BitNet/models/bitnet-b1.58-2B-4T

# We need to replace BitNet/src/ggml-bitnet-mad.cpp with our patched version 
# to fix the clang error about discarding 'const' qualifier.
COPY Patch/ggml-bitnet-mad.cpp /app/BitNet/src/ggml-bitnet-mad.cpp

# Fixes an issue with setup reinstalling packages unnecessarily
COPY Patch/setup_env.py /app/BitNet/setup_env.py

WORKDIR /app/BitNet

# Install BitNet requirements
RUN sed -i '/^torch/d' requirements.txt && \
    pip install --no-cache-dir -r requirements.txt

# Codegen
RUN python utils/codegen_tl2.py \
    --model Llama3-8B-1.58-100B-tokens \
    --BM 256,128,256,128 \
    --BK 96,96,96,96 \
    --bm 32,32,32,32

ENV GGML_DISABLE_MAD=1

# Configure + build with Alpine clang
RUN cmake -B build \
    -DBITNET_X86_TL2=ON \
    -DCMAKE_C_COMPILER=clang \
    -DCMAKE_CXX_COMPILER=clang++

RUN cmake --build build --target llama-cli --config Release

# Run
CMD ["python3", "run_inference.py", "-m", "/app/ggml-model-i2_s.gguf", "-p", "You are a helpful assistant. Always follow the user's instructions.", "-cnv"]


